**Structured Document Data Extractor API** using a **Django/DRF** backend for file uploads and **LangChain** with OpenAI for intelligent, **Structured Output** extraction.

---

## 1. Project Overview and Stack

| **Component**     | **Role**                                                           | **Technology Used**                      |
| ----------------------- | ------------------------------------------------------------------------ | ---------------------------------------------- |
| **Backend/API**   | Handles file uploads, routing, and serves the API endpoint.              | **Django / Django REST Framework (DRF)** |
| **AI/Extraction** | Dynamically generates Pydantic schemas and runs the extraction pipeline. | **LangChain**(with `langchain-openai`) |
| **Schema**        | Defines the required JSON structure for the LLM output.                  | **Pydantic**(`create_model`)           |
| **PDF Handling**  | Loads text content from the uploaded PDF document.                       | **pypdf**(`PyPDFLoader`)               |

---

## 2. LangChain Extraction Service (`extractor/lc_service.py`)

This module encapsulates the core LLM logic, ensuring modularity.

### A. Dynamic Pydantic Schema Generation

The key function converts a user-defined string (e.g., "Name, ID") into a valid Pydantic model. This model is then used to enforce the output structure of the LLM.

* **Function:** `create_extraction_schema(field_string: str) -> Type[BaseModel]`
* **Process:**
  1. Splits the comma-separated `field_string`.
  2. Normalizes field names to snake_case (e.g., "Total Amount" becomes `total_amount`).
  3. Uses `pydantic.create_model` to build a new `BaseModel` class, with fields set to `Optional[str] = None` and a detailed description to guide the LLM.

### B. The LangChain Chain

This function executes the structured extraction using the dynamic schema.

* **Function:** `run_extraction_chain(document_text: str, schema: Type[BaseModel]) -> Dict[str, Any]`
* **Pipeline (`prompt | structured_llm`):**
  1. **Initialize LLM:** `ChatOpenAI(model="gpt-4o-mini")` is used, with `temperature=0.0` for high accuracy.
  2. **Bind Schema:** The LLM is wrapped using `.with_structured_output(schema)`, which forces the model to return a JSON object conforming to the dynamically created Pydantic schema.
  3. **Prompt:** A `SYSTEM_TEMPLATE` is used to instruct the LLM to act as an "expert document data extraction specialist" and **CRITICALLY** set missing fields to `null`.
  4. **Invocation:** The chain is invoked with the document text, and the resulting Pydantic model is converted to a dictionary (`model_dump()`) for the API response.

---

## 3. DRF API Implementation

The Django REST Framework handles the file upload and coordinates the extraction service.

### A. Serializer (`extractor/serializers.py`)

* **Class:** `ExtractionRequestSerializer`
* **Fields:**
  * `document` (serializers.FileField): The uploaded PDF file.
  * `fields` (serializers.CharField): The comma-separated string of data points to extract.
* **Validation:** Includes a check to ensure only `.pdf` files are uploaded.

### B. View (`extractor/views.py`)

* **Class:** `StructuredExtractorAPIView(APIView)`
* **Parsers:** Uses `MultiPartParser` and `FormParser` to correctly handle file uploads (`multipart/form-data`).
* **`post` Method Logic:**
  1. **Validation:** Serializes the request data.
  2. **File Handling:** The uploaded file is temporarily saved to disk using `tempfile.NamedTemporaryFile` because the `PyPDFLoader` requires a file path.
  3. **Text Loading:** `PyPDFLoader` loads the file, and page contents are joined into a single `document_text` string.
  4. **Extraction:** Calls `create_extraction_schema` and `run_extraction_chain`.
  5. **Response:** Returns the extracted data dictionary as a JSON response (HTTP 200).
  6. **Cleanup:** A **CRITICAL** `finally` block ensures the temporary file is deleted after processing.

### C. URLs Configuration

The API is exposed at the path `/api/v1/extract/`.

* **`extractor/urls.py`:** `path('extract/', StructuredExtractorAPIView.as_view(), name='structured-extract')`
* **`core/urls.py`:** Hooks up the app: `path('api/v1/', include('extractor.urls'))`

---

## 4. API Testing

The API is tested using a **POST** request with `multipart/form-data` encoding.

* **Method:** `POST`
* **URL:** `http://127.0.0.1:8000/api/v1/extract/`
* **Body (form-data):**
  * **Key:** `document`, **Type:** `File` (select your PDF).
  * **Key:** `fields`, **Type:** `Text`, **Value:** (e.g., `"Invoice Number, Date Issued, Customer Name"`)

Would you like me to elaborate on the **Pydantic schema generation** or the  **LangChain structured output binding** ?
